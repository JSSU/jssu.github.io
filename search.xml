<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>uber_be</title>
      <link href="/2022/09/27/uber-be/"/>
      <url>/2022/09/27/uber-be/</url>
      
        <content type="html"><![CDATA[<h2 id="Designing-Uber-backend"><a href="#Designing-Uber-backend" class="headerlink" title="Designing Uber backend"></a>Designing Uber backend</h2><p>Let’s design a ride-sharing service like Uber, which connects passengers who need a ride with drivers who have a car.</p><!-- toc --><ul><li><a href="#1-what-is-uber-">1. What is Uber?</a></li><li><a href="#2-requirements-and-goals-of-the-system">2. Requirements and Goals of the System</a></li><li><a href="#3-capacity-estimation-and-constraints">3. Capacity Estimation and Constraints</a></li><li><a href="#4-basic-system-design-and-algorithm">4. Basic System Design and Algorithm</a></li><li><a href="#5-fault-tolerance-and-replication">5. Fault Tolerance and Replication</a></li><li><a href="#6-ranking">6. Ranking</a></li><li><a href="#7-advanced-issues">7. Advanced Issues</a></li></ul><!-- tocstop --><h3 id="1-What-is-Uber"><a href="#1-What-is-Uber" class="headerlink" title="1. What is Uber?"></a>1. What is Uber?</h3><p>Uber enables its customers to book drivers for taxi rides. Uber drivers use their personal cars to drive customers around. Both customers and drivers communicate with each other through their smartphones using the Uber app.</p><h3 id="2-Requirements-and-Goals-of-the-System"><a href="#2-Requirements-and-Goals-of-the-System" class="headerlink" title="2. Requirements and Goals of the System"></a>2. Requirements and Goals of the System</h3><p>Let’s start with building a simpler version of Uber.</p><p>There are two types of users in our system: 1) Drivers 2) Customers.</p><ul><li>Drivers need to regularly notify the service about their current location and their availability to pick passengers.</li><li>Passengers get to see all the nearby available drivers.</li><li>Customer can request a ride; nearby drivers are notified that a customer is ready to be picked up.</li><li>Once a driver and a customer accept a ride, they can constantly see each other’s current location until the trip finishes.</li><li>Upon reaching the destination, the driver marks the journey complete to become available for the next ride.</li></ul><h3 id="3-Capacity-Estimation-and-Constraints"><a href="#3-Capacity-Estimation-and-Constraints" class="headerlink" title="3. Capacity Estimation and Constraints"></a>3. Capacity Estimation and Constraints</h3><ul><li>Let’s assume we have 300M customers and 1M drivers with 1M daily active customers and 500K daily active drivers.</li><li>Let’s assume 1M daily rides.</li><li>Let’s assume that all active drivers notify their current location every three seconds.</li><li>Once a customer puts in a request for a ride, the system should be able to contact drivers in real-time.</li></ul><h3 id="4-Basic-System-Design-and-Algorithm"><a href="#4-Basic-System-Design-and-Algorithm" class="headerlink" title="4. Basic System Design and Algorithm"></a>4. Basic System Design and Algorithm</h3><p>We will take the solution discussed in Designing <a href="https://jssu.github.io/2022/09/26/yelp-nearby-friends/">Yelp</a> and modify it to make it work for the above-mentioned “Uber” use cases. The biggest difference we have is that our QuadTree was not built keeping in mind that there would be frequent updates to it. So, we have two issues with our Dynamic Grid solution:</p><ul><li>Since all active drivers are reporting their locations every three seconds, we need to update our data structures to reflect that. If we have to update the QuadTree for every change in the driver’s position, it will take a lot of time and resources. To update a driver to its new location, we must find the right grid based on the driver’s previous location. If the new position does not belong to the current grid, we must remove the driver from the current grid and move&#x2F;reinsert the user to the correct grid. After this move, if the new grid reaches the maximum limit of drivers, we have to repartition it.</li><li>We need to have a quick mechanism to propagate the current location of all the nearby drivers to any active customer in that area. Also, when a ride is in progress, our system needs to notify both the driver and passenger about the current location of the car.</li></ul><p>Although our QuadTree helps us find nearby drivers quickly, a fast update in the tree is not guaranteed.</p><p><strong>Do we need to modify our QuadTree every time a driver reports their location?</strong> If we don’t update our QuadTree with every update from the driver, it will have some old data and will not reflect the current location of drivers correctly. If you recall, our purpose of building the QuadTree was to find nearby drivers (or places) efficiently. Since all active drivers report their location every three seconds, therefore there will be a lot more updates happening to our tree than querying for nearby drivers. So, what if we keep the latest position reported by all drivers in a hash table and update our QuadTree a little less frequently? Let’s assume we guarantee that a driver’s current location will be reflected in the QuadTree within 15 seconds. Meanwhile, we will maintain a hash table that will store the current location reported by drivers; let’s call this DriverLocationHT.</p><p><strong>How much memory we need for DriverLocationHT?</strong> We need to store DriveID, their present and old location, in the hash table. So, we need a total of 35 bytes to store one record:</p><ol><li>DriverID (3 bytes - 1 million drivers)</li><li>Old latitude (8 bytes)</li><li>Old longitude (8 bytes)</li><li>New latitude (8 bytes)</li><li>New longitude (8 bytes) Total &#x3D; 35 bytes</li></ol><p>If we have 1 million total drivers, we need the following memory (ignoring hash table overhead):</p><center>1 million * 35 bytes => 35 MB</center><p><strong>How much bandwidth will our service consume to receive location updates from all drivers?</strong> If we get DriverID and their location, it will be (3+16 &#x3D;&gt; 19 bytes). If we receive this information every three seconds from 500K daily active drivers, we will be getting 9.5MB per three seconds.</p><p><strong>Do we need to distribute DriverLocationHT onto multiple servers?</strong> Although our memory and bandwidth requirements don’t require this, since all this information can easily be stored on one server but, for scalability, performance, and fault tolerance, we should distribute DriverLocationHT onto multiple servers. We can distribute based on the DriverID to make the distribution completely random. Let’s call the machines holding DriverLocationHT the Driver Location server. Other than storing the driver’s location, each of these servers will do two things:</p><ol><li>As soon as the server receives an update for a driver’s location, they will broadcast that information to all the interested customers.</li><li>The server needs to notify the respective QuadTree server to refresh the driver’s location. As discussed above, this can happen every 15 seconds.</li></ol><p><strong>How can we efficiently broadcast the driver’s location to customers?</strong> We can have a Push Model where the server will push the positions to all the relevant users. <em>We can have a dedicated Notification Service that can broadcast drivers’ current location to all the interested customers.</em> We can build our Notification service on a publisher&#x2F;subscriber model. When customers open the Uber app on their cell phones, they query the server to find nearby drivers. On the server-side, before returning the list of drivers to the customer, we will subscribe the customer for all the updates from those drivers. We can maintain a list of customers (subscribers) interested in knowing the location of a driver and, whenever we have an update in DriverLocationHT for that driver, we can broadcast the current location of the driver to all subscribed customers. This way, our system makes sure that we always show the driver’s current position to the customer.</p><p><strong>How much memory will we need to store all these subscriptions?</strong> As we have estimated above, we will have 1M daily active customers and 500K daily active drivers. On average, let’s assume that five customers subscribe to one driver. Let’s assume we store all this information in a hash table so that we can update it efficiently. We need to store driver and customer IDs to maintain the subscriptions. Assuming we will need 3 bytes for DriverID and 8 bytes for CustomerID, we will need 21MB of memory.</p><center>(500K * 3) + (500K * 5 * 8 ) ~= 21 MB</center><p><strong>How much bandwidth will we need to broadcast the driver’s location to customers?</strong> For every active driver, we have five subscribers, so the total subscribers we have:</p><center>5 * 500K => 2.5M</center><p>To all these customers we need to send DriverID (3 bytes) and their location (16 bytes) every second, so, we need the following bandwidth:</p><center>2.5M * 19 bytes => 47.5 MB/s</center><p><strong>How can we efficiently implement the Notification service?</strong> We can either use HTTP long polling or push notifications.</p><p><strong>How will the new publishers&#x2F;drivers get added for a current customer?</strong> As we have proposed above, customers will be subscribed to nearby drivers when they open the Uber app for the first time; what will happen when a new driver enters the area the customer is looking at? To add a new customer&#x2F;driver subscription dynamically, we need to keep track of the area the customer is watching. This will make our solution complicated; what if, instead of pushing this information, clients pull it from the server?</p><p><strong>How about if clients pull information about nearby drivers from the server?</strong> Clients can send their current location, and the server will find all the nearby drivers from the QuadTree to return them to the client. Upon receiving this information, the client can update their screen to reflect the current positions of the drivers. Clients can query every five seconds to limit the number of round trips to the server. This solution looks simpler compared to the push model described above.</p><p><strong>Do we need to repartition a grid as soon as it reaches the maximum limit?</strong> We can have a cushion to let each grid grow a little bigger beyond the limit before we decide to partition it. Let’s say our grids can grow&#x2F;shrink an extra 10% before we partition&#x2F;merge them. This should decrease the load for a grid partition or merge on high traffic grids.</p><p><img src="https://scontent-sjc3-1.xx.fbcdn.net/v/t39.30808-6/309624435_10220950724453425_6177512686405739293_n.jpg?_nc_cat=102&ccb=1-7&_nc_sid=0debeb&_nc_ohc=N6zcPvdmgNQAX9tQwsR&_nc_ht=scontent-sjc3-1.xx&oh=00_AT9iGzfBwNisBoRf8IfpfCV172Wk1X67BkPXxlTlVM-o6A&oe=63383BD2" alt="image"></p><p><strong>How would “Request Ride” use case work?</strong></p><ol><li>The customer will put a request for a ride.</li><li>One of the Aggregator servers will take the request and asks QuadTree servers to return nearby drivers.</li><li>The Aggregator server collects all the results and sorts them by ratings.</li><li>The Aggregator server will send a notification to the top (say three) drivers simultaneously, whichever driver accepts the request first will be assigned the ride. The other drivers will receive a cancellation request. If none of the three drivers respond, the Aggregator will request a ride from the next three drivers from the list.</li><li>Once a driver accepts a request, the customer is notified.</li></ol><h3 id="5-Fault-Tolerance-and-Replication"><a href="#5-Fault-Tolerance-and-Replication" class="headerlink" title="5. Fault Tolerance and Replication"></a>5. Fault Tolerance and Replication</h3><p><strong>What if a Driver Location server or Notification server dies?</strong> We would need replicas of these servers, so that if the primary dies the secondary can take control. Also, we can store this data in some persistent storage like SSDs that can provide fast IOs; this will ensure that if both primary and secondary servers die we can recover the data from the persistent storage.</p><h3 id="6-Ranking"><a href="#6-Ranking" class="headerlink" title="6. Ranking"></a>6. Ranking</h3><p>How about if we want to rank the search results not just by proximity but also by popularity or relevance?</p><p><strong>How can we return top rated drivers within a given radius?</strong> Let’s assume we keep track of the overall ratings of each driver in our database and QuadTree. An aggregated number can represent this popularity in our system, e.g., how many stars does a driver get out of ten? While searching for the top 10 drivers within a given radius, we can ask each partition of the QuadTree to return the top 10 drivers with a maximum rating. The aggregator server can then determine the top 10 drivers among all the drivers returned by different partitions.</p><h3 id="7-Advanced-Issues"><a href="#7-Advanced-Issues" class="headerlink" title="7. Advanced Issues"></a>7. Advanced Issues</h3><ol><li>How will we handle clients on slow and disconnecting networks?</li><li>What if a client gets disconnected when they are a part of a ride? How will we handle billing in such a scenario?</li><li>How about if clients pull all the information, compared to servers always pushing it</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> sysDesign </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>yelp_nearby_friends</title>
      <link href="/2022/09/26/yelp-nearby-friends/"/>
      <url>/2022/09/26/yelp-nearby-friends/</url>
      
        <content type="html"><![CDATA[<h1 id="Designing-Yelp-or-Nearby-Friends"><a href="#Designing-Yelp-or-Nearby-Friends" class="headerlink" title="Designing Yelp or Nearby Friends"></a>Designing Yelp or Nearby Friends</h1><span id="more"></span><p>Let’s design a Yelp like service, where users can search for nearby places like restaurants, theaters, or shopping malls, etc., and can also add&#x2F;view reviews of places.</p><h2 id="1-Why-Yelp-or-Proximity-Server"><a href="#1-Why-Yelp-or-Proximity-Server" class="headerlink" title="1. Why Yelp or Proximity Server?"></a>1. Why Yelp or Proximity Server?</h2><p>Proximity servers are used to discover nearby attractions like places, events, etc. If you haven’t used yelp.com before, please try it before proceeding (you can search for nearby restaurants, theaters, etc.) and spend some time understanding different options that the website offers. This will help you a lot in understanding this chapter better.</p><h2 id="2-Requirements-and-Goals-of-the-System"><a href="#2-Requirements-and-Goals-of-the-System" class="headerlink" title="2. Requirements and Goals of the System"></a>2. Requirements and Goals of the System</h2><p><strong>What do we wish to achieve from a Yelp like service?</strong> Our service will be storing information about different places so that users can perform a search on them. Upon querying, our service will return a list of places around the user.</p><p>Our Yelp-like service should meet the following requirements:</p><p><strong>Functional Requirements:</strong></p><ol><li>Users should be able to add&#x2F;delete&#x2F;update Places.</li><li>Given their location (longitude&#x2F;latitude), users should be able to find all nearby places within a given radius.</li><li>Users should be able to add feedback&#x2F;review about a place. The feedback can have pictures, text, and a rating.</li></ol><p><strong>Non-functional Requirements:</strong></p><ol><li>Users should have a real-time search experience with minimum latency.</li><li>Traffic - Our service should support a heavy search load. There will be a lot of search requests compared to adding a new place.</li></ol><h2 id="3-Scale-Estimation"><a href="#3-Scale-Estimation" class="headerlink" title="3. Scale Estimation"></a>3. Scale Estimation</h2><p>Let’s build our system assuming that we have 500M places and 100K queries per second (QPS). Let’s also assume a 20% growth in the number of places and QPS each year.</p><h2 id="4-Database-Schema"><a href="#4-Database-Schema" class="headerlink" title="4. Database Schema"></a>4. Database Schema</h2><p>Each Place can have the following fields:</p><ol><li>LocationID (8 bytes): Uniquely identifies a location.</li><li>Name (256 bytes)</li><li>Latitude (8 bytes)</li><li>Longitude (8 bytes)</li><li>Description (512 bytes)</li><li>Category (1 byte): E.g., coffee shop, restaurant, theater, etc.</li></ol><p>Although a four bytes number can uniquely identify 500M locations, with future growth in mind, we will go with 8 bytes for LocationID.</p><p>Total size: 8 + 256 + 8 + 8 + 512 + 1 &#x3D;&gt; 793 bytes</p><p>We also need to store reviews, photos, and ratings of a Place. We can have a separate table to store reviews for Places:</p><ol><li>LocationID (8 bytes)</li><li>ReviewID (4 bytes): Uniquely identifies a review, assuming any location will not have more than 2^32 reviews.</li><li>ReviewText (512 bytes)</li><li>Rating (1 byte): how many stars a place gets out of ten.</li></ol><p>Similarly, we can have a separate table to store photos for Places and Reviews.</p><h2 id="5-System-APIs"><a href="#5-System-APIs" class="headerlink" title="5. System APIs"></a>5. System APIs</h2><p>We can have SOAP or REST APIs to expose the functionality of our service. The following could be the definition of the API for searching:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">search(api_dev_key, search_terms, user_location, radius_filter, maximum_results_to_return, </span><br><span class="line">    category_filter, sort, page_token)</span><br></pre></td></tr></table></figure><p><strong>Parameters:</strong></p><ul><li>api_dev_key (string): The API developer key of a registered account. This will be used to, among other things, throttle users based on their allocated quota.</li><li>search_terms (string): A string containing the search terms.</li><li>user_location (string): Location of the user performing the search.</li><li>radius_filter (number): Optional search radius in meters.</li><li>maximum_results_to_return (number): Number of business results to return.</li><li>category_filter (string): Optional category to filter search results, e.g., Restaurants, Shopping Centers, etc.</li><li>sort (number): Optional sort mode: Best matched (0 - default), Minimum distance (1), Highest rated (2).</li><li>page_token (string): This token will specify a page in the result set that should be returned.</li></ul><p><strong>Returns</strong>: (JSON)<br>A JSON containing information about a list of businesses matching the search query. Each result entry will have the business name, address, category, rating, and thumbnail.</p><h2 id="6-Basic-System-Design-and-Algorithm"><a href="#6-Basic-System-Design-and-Algorithm" class="headerlink" title="6. Basic System Design and Algorithm"></a>6. Basic System Design and Algorithm</h2><p>At a high level, we need to store and index each dataset described above (places, reviews, etc.). For users to query this massive database, the indexing should be read efficient, since while searching for the nearby places users expect to see the results in real-time.</p><p>Given that the location of a place doesn’t change that often, we don’t need to worry about frequent updates of the data. As a contrast, if we intend to build a service where objects do change their location frequently, e.g., people or taxis, then we might come up with a very different design.</p><p>Let’s see what are different ways to store this data and also find out which method will suit best for our use cases:</p><h3 id="a-SQL-solution"><a href="#a-SQL-solution" class="headerlink" title="a. SQL solution"></a>a. SQL solution</h3><p>One simple solution could be to store all the data in a database like MySQL. Each place will be stored in a separate row, uniquely identified by LocationID. Each place will have its longitude and latitude stored separately in two different columns, and to perform a fast search; we should have indexes on both these fields.</p><p>To find all the nearby places of a given location (X, Y) within a radius ‘D’, we can query like this:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> Places</span><br><span class="line"><span class="keyword">where</span> Latitude <span class="keyword">between</span> X<span class="operator">-</span>D <span class="keyword">and</span> X<span class="operator">+</span>D </span><br><span class="line">  <span class="keyword">and</span> Longitude <span class="keyword">between</span> Y<span class="operator">-</span>D <span class="keyword">and</span> Y<span class="operator">+</span>D</span><br></pre></td></tr></table></figure><p>The above query is not completely accurate, as we know that to find the distance between two points we have to use the distance formula (Pythagorean theorem), but for simplicity let’s take this.</p><p><strong>How efficient would this query be?</strong> We have estimated 500M places to be stored in our service. Since we have two separate indexes, each index can return a huge list of places and performing an intersection on those two lists won’t be efficient. Another way to look at this problem is that there could be too many locations between ‘X-D’ and ‘X+D’, and similarly between ‘Y-D’ and ‘Y+D’. If we can somehow shorten these lists, it can improve the performance of our query.</p><h3 id="b-Grids"><a href="#b-Grids" class="headerlink" title="b. Grids"></a>b. Grids</h3><p>We can divide the whole map into smaller grids to group locations into smaller sets. Each grid will store all the Places residing within a specific range of longitude and latitude. This scheme would enable us to query only a few grids to find nearby places. Based on a given location and radius, we can find all the neighboring grids and then query these grids to find nearby places.</p><p><img src="https://scontent-sjc3-1.xx.fbcdn.net/v/t39.30808-6/309149000_10220946452506629_7105713191113436879_n.jpg?_nc_cat=103&ccb=1-7&_nc_sid=0debeb&_nc_ohc=XDohN0KRYNAAX9XNAOy&_nc_ht=scontent-sjc3-1.xx&oh=00_AT8EiiFyxmvYDMET7XLhOqAweCxRecMz2qXshkvtOIwNPA&oe=6336C6D5" alt="image"></p><p>Let’s assume that GridID (a four bytes number) would uniquely identify grids in our system.</p><p><strong>What could be a reasonable grid size?</strong> Grid size could be equal to the distance we would like to query since we also want to reduce the number of grids. If the grid size is equal to the distance we want to query, then we only need to search within the grid which contains the given location and neighboring eight grids. Since our grids would be statically defined (from the fixed grid size), we can easily find the grid number of any location (lat, long) and its neighboring grids.</p><p>In the database, we can store the GridID with each location and have an index on it, too, for faster searching. Now, our query will look like:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> Places </span><br><span class="line"><span class="keyword">where</span> Latitude <span class="keyword">between</span> X<span class="operator">-</span>D <span class="keyword">and</span> X<span class="operator">+</span>D </span><br><span class="line">  <span class="keyword">and</span> Longitude <span class="keyword">between</span> Y<span class="operator">-</span>D <span class="keyword">and</span> Y<span class="operator">+</span>D </span><br><span class="line">  <span class="keyword">and</span> GridID <span class="keyword">in</span> (GridID, GridID1, GridID2, ..., GridID8)</span><br></pre></td></tr></table></figure><p>This will undoubtedly improve the runtime of our query.</p><p><strong>Should we keep our index in memory?</strong> Maintaining the index in memory will improve the performance of our service. We can keep our index in a hash table where ‘key’ is the grid number and ‘value’ is the list of places contained in that grid.</p><p><strong>How much memory will we need to store the index?</strong> Let’s assume our search radius is 10 miles; given that the total area of the earth is around 200 million square miles, we will have 20 million grids. We would need a four bytes number to uniquely identify each grid and, since LocationID is 8 bytes, we would need 4GB of memory (ignoring hash table overhead) to store the index.</p><center> (4 * 20M) + (8 * 500M) ~= 4 GB </center><p>This solution can still run slow for those grids that have a lot of places since our places are not uniformly distributed among grids. We can have a thickly dense area with a lot of places, and on the other hand, we can have areas which are sparsely populated.</p><p>This problem can be solved if we can dynamically adjust our grid size such that whenever we have a grid with a lot of places we break it down to create smaller grids. A couple of challenges with this approach could be: 1) how to map these grids to locations and 2) how to find all the neighboring grids of a grid.</p><h3 id="c-Dynamic-size-grids"><a href="#c-Dynamic-size-grids" class="headerlink" title="c. Dynamic size grids"></a>c. Dynamic size grids</h3><p>Let’s assume we don’t want to have more than 500 places in a grid so that we can have a faster searching. So, whenever a grid reaches this limit, we break it down into four grids of equal size and distribute places among them. This means thickly populated areas like downtown San Francisco will have a lot of grids, and sparsely populated area like the Pacific Ocean will have large grids with places only around the coastal lines.</p><p><strong>What data-structure can hold this information?</strong> A tree in which each node has four children can serve our purpose. Each node will represent a grid and will contain information about all the places in that grid. If a node reaches our limit of 500 places, we will break it down to create four child nodes under it and distribute places among them. In this way, all the leaf nodes will represent the grids that cannot be further broken down. So leaf nodes will keep a list of places with them. This tree structure in which each node can have four children is called a <a href="https://en.wikipedia.org/wiki/Quadtree">QuadTree</a></p><p><img src="https://scontent-sjc3-1.xx.fbcdn.net/v/t39.30808-6/305638304_10220946481067343_3475970560453112676_n.jpg?_nc_cat=105&ccb=1-7&_nc_sid=0debeb&_nc_ohc=p7H3iEZ0jO8AX9yyB1-&_nc_ht=scontent-sjc3-1.xx&oh=00_AT9p7VxOfUhbGCwmZNcKODfiXMsx7Hnms86RwDSueXKLRw&oe=6337381E" alt="image"></p><p><strong>How will we build a QuadTree?</strong> We will start with one node that will represent the whole world in one grid. Since it will have more than 500 locations, we will break it down into four nodes and distribute locations among them. We will keep repeating this process with each child node until there are no nodes left with more than 500 locations.</p><p><strong>How will we find the grid for a given location?</strong> We will start with the root node and search downward to find our required node&#x2F;grid. At each step, we will see if the current node we are visiting has children. If it has, we will move to the child node that contains our desired location and repeat this process. If the node does not have any children, then that is our desired node.</p><p><strong>How will we find neighboring grids of a given grid?</strong> Since only leaf nodes contain a list of locations, we can connect all leaf nodes with a doubly linked list. This way we can iterate forward or backward among the neighboring leaf nodes to find out our desired locations. Another approach for finding adjacent grids would be through parent nodes. We can keep a pointer in each node to access its parent, and since each parent node has pointers to all of its children, we can easily find siblings of a node. We can keep expanding our search for neighboring grids by going up through the parent pointers.</p><p>Once we have nearby LocationIDs, we can query the backend database to find details about those places.</p><p><strong>What will be the search workflow?</strong> We will first find the node that contains the user’s location. If that node has enough desired places, we can return them to the user. If not, we will keep expanding to the neighboring nodes (either through the parent pointers or doubly linked list) until either we find the required number of places or exhaust our search based on the maximum radius.</p><p><strong>How much memory will be needed to store the QuadTree?</strong> For each Place, if we cache only LocationID and Lat&#x2F;Long, we would need 12GB to store all places.</p><center> 24 * 500M => 12 GB </center><p>Since each grid can have a maximum of 500 places, and we have 500M locations, how many total grids we will have?</p><center>500M / 500 => 1M grids</center><p>Which means we will have 1M leaf nodes and they will be holding 12GB of location data. A QuadTree with 1M leaf nodes will have approximately 1&#x2F;3rd internal nodes, and each internal node will have 4 pointers (for its children). If each pointer is 8 bytes, then the memory we need to store all internal nodes would be:</p><center>1M * 1/3 * 4 * 8 = 10 MB</center><p>So, total memory required to hold the whole QuadTree would be 12.01GB. This can easily fit into a modern-day server.</p><p><strong>How would we insert a new Place into our system?</strong> Whenever a new Place is added by a user, we need to insert it into the databases as well as in the QuadTree. If our tree resides on one server, it is easy to add a new Place, but if the QuadTree is distributed among different servers, first we need to find the grid&#x2F;server of the new Place and then add it there (discussed in the next section).</p><h2 id="7-Data-Partitioning"><a href="#7-Data-Partitioning" class="headerlink" title="7. Data Partitioning"></a>7. Data Partitioning</h2><p>What if we have a huge number of places such that our index does not fit into a single machine’s memory? With 20% growth each year we will reach the memory limit of the server in the future. Also, what if one server cannot serve the desired read traffic? To resolve these issues, we must partition our QuadTree!</p><p>We will explore two solutions here (both of these partitioning schemes can be applied to databases, too):</p><p><strong>a. Sharding based on regions</strong>: We can divide our places into regions (like zip codes), such that all places belonging to a region will be stored on a fixed node. To store a place we will find the server through its region and, similarly, while querying for nearby places we will ask the region server that contains user’s location. This approach has a couple of issues:</p><ol><li>What if a region becomes hot? There would be a lot of queries on the server holding that region, making it perform slow. This will affect the performance of our service.</li><li>Over time, some regions can end up storing a lot of places compared to others. Hence, maintaining a uniform distribution of places, while regions are growing is quite difficult.</li></ol><p>To recover from these situations, either we have to repartition our data or use consistent hashing.</p><p><strong>b. Sharding based on LocationID</strong>: Our hash function will map each LocationID to a server where we will store that place. While building our QuadTree, we will iterate through all the places and calculate the hash of each LocationID to find a server where it would be stored. To find places near a location, we have to query all servers and each server will return a set of nearby places. A centralized server will aggregate these results to return them to the user.</p><p><strong>Will we have different QuadTree structure on different partitions?</strong> Yes, this can happen since it is not guaranteed that we will have an equal number of places in any given grid on all partitions. However, we do make sure that all servers have approximately an equal number of Places. This different tree structure on different servers will not cause any issue though, as we will be searching all the neighboring grids within the given radius on all partitions.</p><p>The remaining part of this chapter assumes that we have partitioned our data based on LocationID.</p><h2 id="8-Replication-and-Fault-Tolerance"><a href="#8-Replication-and-Fault-Tolerance" class="headerlink" title="8. Replication and Fault Tolerance"></a>8. Replication and Fault Tolerance</h2><p>Having replicas of QuadTree servers can provide an alternate to data partitioning. To distribute read traffic, we can have replicas of each QuadTree server. We can have a primary-secondary configuration where replicas (secondaries) will only serve read traffic; all write traffic will first go to the primary and then applied to secondaries. Secondaries might not have some recently inserted places (a few milliseconds delay will be there), but this could be acceptable.</p><p>What will happen when a QuadTree server dies? We can have a secondary replica of each server and, if the primary dies, it can take control after the failover. Both primary and secondary servers will have the same QuadTree structure.</p><p><strong>What if both primary and secondary servers die at the same time?</strong> We have to allocate a new server and rebuild the same QuadTree on it. How can we do that, since we don’t know what places were kept on this server? The brute-force solution would be to iterate through the whole database and filter LocationIDs using our hash function to figure out all the required places that will be stored on this server. This would be inefficient and slow; also, during the time when the server is being rebuilt, we will not be able to serve any query from it, thus missing some places that should have been seen by users.</p><p><strong>How can we efficiently retrieve a mapping between Places and QuadTree server?</strong> We have to build a reverse index that will map all the Places to their QuadTree server. We can have a separate QuadTree Index server that will hold this information. We will need to build a HashMap where the ‘key’ is the QuadTree server number and the ‘value’ is a HashSet containing all the Places being kept on that QuadTree server. We need to store LocationID and Lat&#x2F;Long with each place because information servers can build their QuadTrees through this. Notice that we are keeping Places’ data in a HashSet, this will enable us to add&#x2F;remove Places from our index quickly. So now, whenever a QuadTree server needs to rebuild itself, it can simply ask the QuadTree Index server for all the Places it needs to store. This approach will surely be quite fast. We should also have a replica of the QuadTree Index server for fault tolerance. If a QuadTree Index server dies, it can always rebuild its index from iterating through the database.</p><p><img src="https://scontent-sjc3-1.xx.fbcdn.net/v/t39.30808-6/309180254_10220946559909314_385458177550335166_n.jpg?_nc_cat=106&ccb=1-7&_nc_sid=0debeb&_nc_ohc=ch7NsqiUQfwAX9Di7Tt&_nc_ht=scontent-sjc3-1.xx&oh=00_AT_ES2TFEGbvJh9G_nlIrhDN7X5-HDnRntkoFVe90xKAfw&oe=63367979" alt="image"></p><h2 id="9-Cache"><a href="#9-Cache" class="headerlink" title="9. Cache"></a>9. Cache</h2><p>To deal with hot Places, we can introduce a cache in front of our database. We can use an off-the-shelf solution like Memcache, which can store all data about hot places. Application servers, before hitting the backend database, can quickly check if the cache has that Place. Based on clients’ usage pattern, we can adjust how many cache servers we need. For cache eviction policy, Least Recently Used (LRU) seems suitable for our system.</p><h2 id="10-Load-Balancing-LB"><a href="#10-Load-Balancing-LB" class="headerlink" title="10. Load Balancing (LB)"></a>10. Load Balancing (LB)</h2><p>We can add LB layer at two places in our system 1) Between Clients and Application servers and 2) Between Application servers and Backend server. Initially, a simple Round Robin approach can be adopted; that will distribute all incoming requests equally among backend servers. This LB is simple to implement and does not introduce any overhead. Another benefit of this approach is if a server is dead the load balancer will take it out of the rotation and will stop sending any traffic to it.</p><p>A problem with Round Robin LB is, it won’t take server load into consideration. If a server is overloaded or slow, the load balancer will not stop sending new requests to that server. To handle this, a more intelligent LB solution would be needed that periodically queries backend server about their load and adjusts traffic based on that.</p><h2 id="11-Ranking"><a href="#11-Ranking" class="headerlink" title="11. Ranking"></a>11. Ranking</h2><p>How about if we want to rank the search results not just by proximity but also by popularity or relevance?</p><p><strong>How can we return most popular places within a given radius?</strong> Let’s assume we keep track of the overall popularity of each place. An aggregated number can represent this popularity in our system, e.g., how many stars a place gets out of ten (this would be an average of different rankings given by users)? We will store this number in the database as well as in the QuadTree. While searching for the top 100 places within a given radius, we can ask each partition of the QuadTree to return the top 100 places with maximum popularity. Then the aggregator server can determine the top 100 places among all the places returned by different partitions.</p><p>Remember that we didn’t build our system to update place’s data frequently. With this design, how can we modify the popularity of a place in our QuadTree? Although we can search a place and update its popularity in the QuadTree, it would take a lot of resources and can affect search requests and system throughput. Assuming the popularity of a place is not expected to reflect in the system within a few hours, we can decide to update it once or twice a day, especially when the load on the system is minimum.</p><!-- toc --><!-- tocstop -->]]></content>
      
      
      
        <tags>
            
            <tag> sysDesign </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>island count</title>
      <link href="/2022/09/21/island-count/"/>
      <url>/2022/09/21/island-count/</url>
      
        <content type="html"><![CDATA[<h2 id="200-Number-of-Islands"><a href="#200-Number-of-Islands" class="headerlink" title="200. Number of Islands"></a>200. Number of Islands</h2><p>Given an <code>m x n</code> 2D binary grid grid which represents a map of ‘1’s (land) and ‘0’s (water), return the number of islands.</p><p>An island is surrounded by water and is formed by connecting adjacent lands horizontally or vertically. You may assume all four edges of the grid are all surrounded by water.</p><h5 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Input: grid = [</span><br><span class="line">  [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;],</span><br><span class="line">  [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;],</span><br><span class="line">  [&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;],</span><br><span class="line">  [&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;1&quot;,&quot;1&quot;]</span><br><span class="line">]</span><br><span class="line">Output: 3</span><br></pre></td></tr></table></figure><h5 id="Solution-O-n-2"><a href="#Solution-O-n-2" class="headerlink" title="Solution O(n^2)"></a>Solution O(n^2)</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// lower_bound/upper_bound example</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span>     <span class="comment">// std::cout</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span>    <span class="comment">// std::lower_bound, std::upper_bound, std::sort</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span>       <span class="comment">// std::vector</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unordered_map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line">    <span class="type">int</span> cnt;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="type">int</span> m;</span><br><span class="line">    <span class="type">int</span> island;</span><br><span class="line">    unordered_map&lt;<span class="type">int</span>, <span class="type">int</span>&gt; map;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">helper</span><span class="params">(<span class="type">int</span> row, <span class="type">int</span> col, vector&lt;vector&lt;<span class="type">char</span>&gt;&gt;&amp; grid)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(row&lt;<span class="number">0</span> || row&gt;= grid.<span class="built_in">size</span>() || col&lt;<span class="number">0</span> || col&gt;=grid[<span class="number">0</span>].<span class="built_in">size</span>() || grid[row][col]==<span class="string">&#x27;0&#x27;</span>) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">if</span>(grid[row][col]==<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            cnt++;</span><br><span class="line">            grid[row][col] = <span class="string">&#x27;0&#x27;</span>;</span><br><span class="line">            <span class="built_in">helper</span>(row<span class="number">-1</span>, col, grid);</span><br><span class="line">            <span class="built_in">helper</span>(row, col<span class="number">-1</span>, grid);</span><br><span class="line">            <span class="built_in">helper</span>(row+<span class="number">1</span>, col, grid);</span><br><span class="line">            <span class="built_in">helper</span>(row, col+<span class="number">1</span>, grid);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">numIslands</span><span class="params">(vector&lt;vector&lt;<span class="type">char</span>&gt;&gt;&amp; grid)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> rows = grid.<span class="built_in">size</span>();</span><br><span class="line">        <span class="type">int</span> cols = grid[<span class="number">0</span>].<span class="built_in">size</span>();</span><br><span class="line">        m =<span class="number">0</span>;</span><br><span class="line">        island = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> row = <span class="number">0</span>; row &lt; rows; row++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> col = <span class="number">0</span>; col &lt; cols; col++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">if</span>(grid[row][col]==<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">                &#123;</span><br><span class="line">                    island++;</span><br><span class="line">                    cnt=<span class="number">0</span>;</span><br><span class="line">                    <span class="built_in">helper</span>(row, col, grid);</span><br><span class="line">                    m = <span class="built_in">max</span>(cnt, m);</span><br><span class="line">                    <span class="keyword">if</span>(map.<span class="built_in">find</span>(cnt) == map.<span class="built_in">end</span>()) &#123;</span><br><span class="line">                        map[cnt] = <span class="number">1</span>;</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        map[cnt]++;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> island;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span> <span class="params">()</span> </span>&#123;</span><br><span class="line"> Solution s;</span><br><span class="line">     vector&lt;vector&lt;<span class="type">char</span>&gt;&gt; m</span><br><span class="line">     &#123;</span><br><span class="line">         &#123;<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;1&#x27;</span>&#125;,</span><br><span class="line">         &#123;<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;0&#x27;</span>&#125;,</span><br><span class="line">         &#123;<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;1&#x27;</span>,<span class="string">&#x27;1&#x27;</span>&#125;,</span><br><span class="line">         &#123;<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;0&#x27;</span>,<span class="string">&#x27;1&#x27;</span>&#125;</span><br><span class="line">     &#125;;</span><br><span class="line"></span><br><span class="line">     </span><br><span class="line">    <span class="comment">//  for (auto row : m) &#123;</span></span><br><span class="line">    <span class="comment">//      for (auto col: row)</span></span><br><span class="line">    <span class="comment">//          cout&lt;&lt; col &lt;&lt;&quot; &quot;;</span></span><br><span class="line">    <span class="comment">//     cout&lt;&lt;endl;</span></span><br><span class="line">    <span class="comment">// &#125;</span></span><br><span class="line"></span><br><span class="line"> cout&lt;&lt;<span class="string">&quot;island cnt: &quot;</span>&lt;&lt;s.<span class="built_in">numIslands</span>(m)&lt;&lt;endl;</span><br><span class="line"> cout&lt;&lt;<span class="string">&quot;max island: &quot;</span>&lt;&lt;s.m&lt;&lt;endl;</span><br><span class="line"> cout&lt;&lt;<span class="string">&quot;island shape map: &quot;</span>&lt;&lt;endl;</span><br><span class="line"> <span class="keyword">for</span> (<span class="keyword">auto</span> item: s.map) &#123;</span><br><span class="line">     cout&lt;&lt;<span class="string">&quot;shape: &quot;</span>&lt;&lt; item.first&lt;&lt;<span class="string">&quot;, cnt: &quot;</span>&lt;&lt; item.second&lt;&lt;endl;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> amazon </tag>
            
            <tag> bfs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2022/09/20/hello-world/"/>
      <url>/2022/09/20/hello-world/</url>
      
        <content type="html"><![CDATA[<p>My old blog: <a href="http://jssu.github.io/jssu.github.com/">jssu.github.io</a></p><span id="more"></span><p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
